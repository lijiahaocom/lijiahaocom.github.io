---
layout:     post
title:      面试知识点索引 
subtitle:   面试知识点索引
date:       2020-01-16
author:     RainbomSea
header-img: img/post-web.jpg
catalog: true
tags:
    - Python
    - Pipenv
---	

787861				

# 机器规划
* k8s 实践
```
T1 	jenkins/kibana/ansible
H1 	gitlab/kafka
H2 	logstash/kafka/zabbix
H3 	elasticeserch
H4 	elasticeserch
```
* 数据库实践
```
T1
H1
H2
H3
H4
```
# 数据库相关
## ELK
### filebeat
* 
### elasticeserch
**Shay的妻子依旧等待着她的食谱搜索……**
**elasticeserch 7.xx 不支持一个索引中简历多个类型并且使用默认类型 _doc**
* 9200 9300
* 常用查询过滤语句
https://es.xiaoleilu.com/054_Query_DSL/60_Query_DSL.html
```
# 在Elasticsearch中存储数据的行为就叫做索引(indexing)

```

* 集群相关命令
https://www.cnblogs.com/qdhxhz/p/11461174.html
* index type id
* 分片，副本
* _search
* _all
* _updata
* _mget
* _bulk
* mapping/templat
* 聚合
```

```
* 生产环境配置
```
#官方文档：
#https://www.elastic.co/guide/en/elasticsearch/reference/7.x/important-settings.html


#参数说明

#如果您正在使用.zip或.tar.gz文件归档，data和logs 目录在 $ES_HOME 下。如果这些重要文件夹保留在默认位置，则Elasticsearch升级到新版本时，很有可能被删除。
#在生产中使用，肯定要更改数据和日志文件夹的位置：
path:
  logs: /var/log/elasticsearch
  data: /var/data/elasticsearch

#补充说明：在生产环境下，应用程序的数据和日志一般需要配置到独立的磁盘分区下。比如/data目录作为独立的数据分区，/var/log作为应用程序日志分区。这样做的好处是，防止因应用程序数据或日志增长，撑爆OS分区。


#某个节点只有和集群下的其他节点共享它的 cluster.name 才能加入一个集群。默认是elasticsearch，但是应该修改为更恰当的，用于描述集群目的的名称。
cluster.name: myes


一定要确保不要在不同的环境中使用相同的集群名称。否则，节点可能会加入错误的集群中。
默认情况下，Elasticsearch 将使用随机生成的uuid的前7个字符作为节点id，请注意，节点ID是持久化的，并且在节点重新启动时不会更改，因此默认节点名称也不会更改。
也可以使用服务器的 HOSTNAME 作为节点的名称。
node.name: ${HOSTNAME}


#默认情况下，Elasticsearch 仅仅绑定回环地址，比如127.0.0.1 和[::1] 。这足以在服务器上运行单个开发节点。
#为了与其他服务器上的节点进行通信并形成集群，你的节点将需要绑定到非环回地址。虽然这里有很多网络相关的配置，但通常只需要配置一下 network.host
network.host: 192.168.60.101

#一旦自定义设置了 network.host ，Elasticsearch 会假定你正在从开发模式转移到生产模式，并将许多系统启动检查从警告升级到异常。
#默认情况下，Elasticsearch假定您正在开发模式下工作。 如果未正确配置上述任何设置，则会向日志文件写入警告，但您将能够启动并运行Elasticsearch节点。
#一旦配置了network.host之类的网络设置，Elasticsearch就会假定您正在转向生产并将上述警告升级为异常。 这些异常将阻止您的Elasticsearch节点启动。 这是一项重要的安全措施，可确保您不会因服务器配置错误而丢失数据。


#在开始生产之前，应该配置两个重要的discovery 和cluster 设置，以便群集中的节点可以相互发现并选择主节点。

discovery.seed_hosts

#开箱即用，没有任何网络配置，Elasticsearch将绑定到可用的环回地址，并将扫描本地端口9300到9305以尝试连接到在同一服务器上运行的其他节点。 这提供了自动集群体验，无需进行任何配置。

如果要在其他主机上形成包含节点的群集，则必须使用discovery.seed_hosts设置提供群集中其他节点的列表，这些节点符合主要条件且可能是实时且可联系的，以便为发现过程设定种子。 此设置通常应包含群集中所有符合主节点的节点的地址。 此设置包含主机数组或逗号分隔的字符串。 每个值应采用host：port或host的形式（其中port默认为设置transport.profiles.default.port，如果未设置则返回transport.port）。 请注意，必须将IPv6主机置于括号内。 此设置的默认值为127.0.0.1，[:: 1]。
discovery.seed_hosts:
   - node1
   - node2
   - node3


#如果未指定，端口将默认为transport.profiles.default.port并回退到transport.port。
#如果主机名解析为多个IP地址，则该节点将尝试发现所有已解析地址的其他节点。


#当您第一次启动全新的Elasticsearch集群时，会出现一个集群引导步骤，该步骤确定在第一次选举中计票的主要合格节点集。 在开发模式下，如果未配置发现设置，则此步骤由节点本身自动执行。 由于此自动引导本质上是不安全的，因此当您在生产模式下启动全新集群时，必须明确列出符合条件的节点的名称或IP地址，这些节点的投票应在第一次选举中计算。 使用cluster.initial_master_nodes设置设置此列表。
cluster.initial_master_nodes:
   - node1 
   - node2 
   - node3 


#初始主节点可以通过其node.name来标识，该节点默认为主机名。 确保cluster.initial_master_nodes中的值与node.name完全匹配。 如果您使用完全限定的域名（例如master-node-a.example.com）作为节点名称，则必须在此列表中使用完全限定名称; 相反，如果node.name是一个没有任何尾随限定符的裸主机名，那么您还必须省略cluster.initial_master_nodes中的尾随限定符。
#初始主节点也可以通过其IP地址识别。


#默认情况下，Elasticsearch告诉JVM使用最小和最大大小为1 GB的堆。 迁移到生产环境时，配置堆大小以确保Elasticsearch有足够的可用堆是很重要的。
#Elasticsearch将通过Xms（最小堆大小）和Xmx（最大堆大小）设置分配jvm.options中指定的整个堆。
#这些设置的值取决于服务器上可用的RAM量。 好的经验法则是：
#Elasticsearch可用的堆越多，它可用于缓存的内存就越多。 但请注意，过多的堆可能会使您陷入长时间的垃圾收集暂停。
#将Xmx设置为不超过物理RAM的50％，以确保有足够的物理RAM留给内核文件系统缓存。
#以下是如何通过jvm.options文件设置堆大小的示例：
#比如公司有一个elasticsearch集群，每个节点是8G内存，那么可以设置如下。

[root@elastic1 elasticsearch-7.0.1]# vi config/jvm.options 

# Xms represents the initial size of total heap space
# Xmx represents the maximum size of total heap space

-Xms4g
-Xmx4g

引用链接：https://blog.csdn.net/chengyuqiang/article/details/89841544
```
### logstash
* grok 
```
# 预定义格式
PATTERN_NAME (?PATTERN)
# 预定义匹配模式 
logstash-7.6.0/vendor/bundle/jruby/2.5.0/gems/logstash-patterns-core-4.1.2/patterns/grok-patterns**
# 正则参考
https://www.runoob.com/regexp/regexp-metachar.html


# 预定义 grok 表达式
TESTA (?:[a-z]+)
TESTLOG %{IP:cip}[" "|-]+%{TESTA:hehe}[" "|-]+%{IP:sip}

# fileter 示例
filter {
	grok {
		match => { "message" => "%{TESTLOG}" }
	}
}

```
* 输入
```
file {
	path => ['/PATH']
	type => "TYPE"
	
	# 开始读取位置
	start_position => "begingning"
}
```
* 输出
```
# 标准输入输出
output {
        stdout {

        }
}

```
### kibana GOEIP
* 图 地图 聚合 桶

### Kafka
* group 瞄一眼
* Kafka manager
```
zookeeper
```
## MySQL
* innodb
* 事务
* 索引
* 查询语句
* 主从 双主 备份恢复 高可用
## mongodb
* 副本集
* 聚合
* 索引
* 备份
## momcache
* 没啥好说的
## rides
* 投票
* 工作原理

# 容器
## docker
* 命名空间
```
UTS 		主机名、域名
IPC 		进程间通信（信号 消息队列 共享内存）
PID  		PID
NetWork 	网络设备、端口等
Mount		挂载点
User		用户和用户组
```

* dockerfile
```
FROM		父镜像
MAINTAINER	维护者信息
RUN			执行命令
ADD			copy 文件 自动解压
COPY		copy 文件 不接压
WORKDIR		工作目录
VOLUME		挂载卷
EXPOSE		打开那个端口
CMD			自动容器启动后的命令
ENTRYPOINT	存在的话 CMD 中的命令会被当做参数
#
docker build -t my/base  .
```

## k8s
* pod 调用过程
* pod 生命周期
* coroDNS
* flannel
* dp
* rs
* ds

* job
* cronJob
* server
* pv pvc 申明

* status
* heml

# 自动化
## zabbix
* 报警
* 报警脚本

## premethus
* 瞄一眼
## Jenkins
* 8080
* maven
* pipoline

## gitlab
* 8080
* webhook
* 通过组长审批合并分支触发

## ansible
* 目录结构
```
配置文件目录		/etc/ansible
执行文件目录 		/usr/bin
主机列表目录		/etc/ansible/hosts
ansible.cfg 读取顺序		当前执行目录 --> 家目录下 --> /etc/anshible

```
* ansible-hoc 指定主机
```
#调用两个主机组的写法，以下webservers和dbservers都会被调用：
ansible webservers:dbservers -m win_ping

#在webservers组中但不在dbsersers中的调用：
ansible webservers:!dbservers -m win_ping

#在webservers组中并且在dbservers组中的才会调用：
ansible webservers:&dbservers -m win_ping

#在调用前加~，代表正则表达式：
ansible ~(web|db).*.91it.org -m win_ping

#组合的例子：
webserver:dbservers:&nginx:!ntp

引用链接：https://www.jianshu.com/p/65b2407950bc 
```
* 常用模块
```


```


# web
## nginx
* 地址重写
* location
* 反向代理
* 异步I/O
## tomcat
* 组件
```
```


# 脚本
## shell
## awk
## python

# Linux
## 系统原理及调优
* cpu
* 硬盘
* 内存

## iptables/netfilter
* 五链
```
		 input 						OUTPUT
		    |						    |
			|							|
			|							|
			|							|
PREROUTING->路由---> FORWARD-----POSTROUTING
```
* 四表
```
filter 过滤报文
nat 地址转换
mangle 拆解报文 修改报文
raw 关闭nat表上启用的链接追踪机制
```
* 动作
```
ACCEPT
DROP		丢弃
REJECT
SNAT
DNAT
MASQUERADE  d动态SNAT
REDIRECT 在本机做端口映射
LOG 
```
## TCP/IP
* 三次握手四次断开
```
C                           S
# 三次握手
| ----SYN-seq=0-ack=0 --->  |
| <-SYN-ACK-seq=0-ack=1---  |
| ----ACK-seq=1=ack=1---->  |
# 四次断开
| ----FIN----seq=100----->  |
| <---ACK-seq=200-ack=101-  |
# 
| <---FIN-seq=250-ack=101-  |
| ---ACK-seq=101-ack=251->  |
```
## HTTP
* 状态码
```
1**
2**
3**
4**
5**
```
* keepalive
* POST PUT HEAD GET DELEAT

## 开机流程
```
开电源
BIOS 自检
MBR 引导
GRUB
加载内核
init
/etc/rc.d/rcX
/etc/rc.local
启动终端
加载环境变量
```


## 硬盘原理 

# 其他
## keepalived 
* VRRP全称Virtual Router Redundancy Protocol
*

## lvs
* 四种模式
* * NAT 反向代理
* * DR 改 MAC 地址，配置vip
* * TUN 隧道 vip
* * FULLNAT  SNAT+DNAT

## 常用端口
